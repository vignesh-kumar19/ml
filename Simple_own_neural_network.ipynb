{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple own Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Input with 3 dimensions\n",
    "#### * 1 hidden layer ( 4 dimensions / nodes) with tanh activation function\n",
    "#### * Output (1 dimension / node) with sigmoid activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.stack.imgur.com/rWFb3.png\" alt=\"Italian Trulli\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([(1.0, 1.0, 0.0, 0.0), (1.0, 0.0, 0.0, 0.0), (1.0, 0.0, 0.0, 0.0)])\n",
    "Y = np.array([[(1.0), (1.0), (0.0), (0.0)]])\n",
    "m = 4\n",
    "n0 = 3\n",
    "n1 = 4\n",
    "n2 = 1\n",
    "learning_rate = 0.1\n",
    "W1 = np.random.randn(n1, n0)\n",
    "W2 = np.random.randn(n2, n1)\n",
    "b1 = np.zeros([n1, 1])\n",
    "b2 = np.zeros([n2, 1])\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual values\n",
      "1.0, 1.0, 1.0 - 1.0\n",
      "1.0, 0.0, 0.0 - 1.0\n",
      "0.0, 0.0, 0.0 - 0.0\n",
      "0.0, 0.0, 0.0 - 0.0\n",
      "\n",
      "Predicted values\n",
      "1.0, 1.0, 1.0 - 0.2977532239411193\n",
      "1.0, 0.0, 0.0 - 0.6000493486076123\n",
      "0.0, 0.0, 0.0 - 0.5\n",
      "0.0, 0.0, 0.0 - 0.5\n"
     ]
    }
   ],
   "source": [
    "Z1 = np.dot(W1, X) + b1\n",
    "A1 = (np.exp(Z1) - np.exp(-Z1)) / (np.exp(Z1) + np.exp(-Z1))\n",
    "Z2 = np.dot(W2, A1) + b2\n",
    "A2 = 1 / (1 + np.exp(-Z2))\n",
    "print(\"Actual values\")\n",
    "for i in range(m):\n",
    "    print(\"{}, {}, {} - {}\".format(X[0][i], X[1][i], X[2][i], Y[0][i]))\n",
    "print()\n",
    "print(\"Predicted values\")\n",
    "for i in range(m):\n",
    "    print(\"{}, {}, {} - {}\".format(X[0][i], X[1][i], X[2][i], A2[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.1942829989822529\n",
      "Loss:  0.10441227158510649\n",
      "Loss:  0.07074893722864972\n",
      "Loss:  0.052301027799265945\n",
      "Loss:  0.040984260054571404\n",
      "Loss:  0.03346737032574689\n",
      "Loss:  0.028166811266528556\n",
      "Loss:  0.024253430199771126\n",
      "Loss:  0.02125823182468831\n",
      "Loss:  0.018898755218868298\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    \n",
    "    # Forward Propagation\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = (np.exp(Z1) - np.exp(-Z1)) / (np.exp(Z1) + np.exp(-Z1))\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = 1 / (1 + np.exp(-Z2))\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        J = (-((Y * np.log(A2)) + ((1 - Y) * np.log(1 - A2)))) / m\n",
    "        J = J.sum() / m\n",
    "        print(\"Loss: \", J )\n",
    "    \n",
    "    # Back propagation\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (np.dot(dZ2, A1.T))\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dA1 = 1 - (np.tanh(10) ** 2)\n",
    "    dZ1 = np.dot(W2.T, dZ2) * dA1 \n",
    "    dW1 = np.dot(dZ1, X.T)\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True)\n",
    "    dW2 /= m\n",
    "    db2 /= m\n",
    "    dW1 /= m\n",
    "    db1 /= m\n",
    "    W2 = W2 - (learning_rate * dW2)\n",
    "    W1 = W1 - (learning_rate * dW1)\n",
    "    b2 = b2 - (learning_rate * db2)\n",
    "    b1 = b1 - (learning_rate * db1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual values\n",
      "1.0, 1.0, 1.0 - 1.0\n",
      "1.0, 0.0, 0.0 - 1.0\n",
      "0.0, 0.0, 0.0 - 0.0\n",
      "0.0, 0.0, 0.0 - 0.0\n",
      "\n",
      "Predicted values\n",
      "1.0, 1.0, 1.0 - 0.9567003071287694\n",
      "1.0, 0.0, 0.0 - 0.9331755671123434\n",
      "0.0, 0.0, 0.0 - 0.07619444784052887\n",
      "0.0, 0.0, 0.0 - 0.07619444784052887\n"
     ]
    }
   ],
   "source": [
    "# Now Forward Propagation result\n",
    "pZ1 = np.dot(W1, X) + b1\n",
    "pA1 = (np.exp(pZ1) - np.exp(-pZ1)) / (np.exp(pZ1) + np.exp(-pZ1))\n",
    "pZ2 = np.dot(W2, pA1) + b2\n",
    "pA2 = 1 / (1 + np.exp(-pZ2))\n",
    "print(\"Actual values\")\n",
    "for i in range(m):\n",
    "    print(\"{}, {}, {} - {}\".format(X[0][i], X[1][i], X[2][i], Y[0][i]))\n",
    "print()\n",
    "print(\"Predicted values\")\n",
    "for i in range(m):\n",
    "    print(\"{}, {}, {} - {}\".format(X[0][i], X[1][i], X[2][i], pA2[0][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
